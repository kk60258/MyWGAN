{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "from six.moves import urllib\n",
    "import tarfile\n",
    "\n",
    "def tfconvert(image):\n",
    "    #return tf.divide(tf.subtract(image, 127.5), 255.0)\n",
    "    return tf.subtract(tf.divide(image, 127.5), 1)\n",
    "\n",
    "def tfrevert(image):\n",
    "#     return tf.add(tf.multiply(image, 255.0), 127.5)\n",
    "    return tf.clip_by_value(tf.multiply(tf.add(image, 1), 127.5), 0, 255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cifar10data:\n",
    "\n",
    "    IMAGE_SIZE = 24\n",
    "\n",
    "    # Global constants describing the CIFAR-10 data set.\n",
    "    NUM_CLASSES = 10\n",
    "    NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 50000\n",
    "    NUM_EXAMPLES_PER_EPOCH_FOR_EVAL = 10000\n",
    "\n",
    "    DATA_URL = 'http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz'\n",
    "    datadir = '/tmp'\n",
    "\n",
    "    def __init__(self, batch_size=10):\n",
    "        self.batch_size = batch_size\n",
    "        bindir = self.maybe_download_and_extract()\n",
    "        self.dataset = self.distorted_inputs(bindir)\n",
    "#         self.dataset = self.dataset.batch(batch_size)\n",
    "        self.dataset = self.dataset.apply(tf.contrib.data.shuffle_and_repeat(buffer_size=1000))\n",
    "        self.dataset = self.dataset.prefetch(buffer_size=batch_size)\n",
    "        self.iterator = self.dataset.make_one_shot_iterator()\n",
    "        self.next_batch = self.iterator.get_next()\n",
    "\n",
    "        self.test_dataset = self.distorted_test_inputs(bindir)\n",
    "#         self.test_dataset = self.test_dataset.batch(batch_size)\n",
    "        self.test_dataset = self.test_dataset.apply(tf.contrib.data.shuffle_and_repeat(buffer_size=1000))\n",
    "#         self.test_iterator = self.test_dataset.make_initializable_iterator()\n",
    "        self.test_iterator = self.test_dataset.make_one_shot_iterator()\n",
    "        self.test_next_batch = self.test_iterator.get_next()\n",
    "\n",
    "    def next_train_batch(self, sess):\n",
    "        train_images, train_labels = sess.run(self.next_batch)\n",
    "        return train_images\n",
    "\n",
    "    def next_test_batch(self, sess):\n",
    "        test_images, test_labels = sess.run(self.test_next_batch)\n",
    "        return test_images\n",
    "\n",
    "    @staticmethod\n",
    "    def maybe_download_and_extract(data_dir=datadir, DATA_URL=DATA_URL):\n",
    "        \"\"\"Download and extract the tarball from Alex's website.\"\"\"\n",
    "        dest_directory = data_dir\n",
    "        if not os.path.exists(dest_directory):\n",
    "            os.makedirs(dest_directory)\n",
    "        filename = DATA_URL.split('/')[-1]\n",
    "        filepath = os.path.join(dest_directory, filename)\n",
    "        if not os.path.exists(filepath):\n",
    "            def _progress(count, block_size, total_size):\n",
    "                sys.stdout.write('\\r>> Downloading %s %.1f%%' % (filename,\n",
    "                                                                 float(count * block_size) / float(total_size) * 100.0))\n",
    "                sys.stdout.flush()\n",
    "            filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)\n",
    "            print()\n",
    "            statinfo = os.stat(filepath)\n",
    "            print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "        extracted_dir_path = os.path.join(dest_directory, 'cifar-10-batches-bin')\n",
    "        if not os.path.exists(extracted_dir_path):\n",
    "            tarfile.open(filepath, 'r:gz').extractall(dest_directory)\n",
    "        return extracted_dir_path\n",
    "\n",
    "    def get_train_inputs(self, data_dir=datadir):\n",
    "\n",
    "        \"\"\"Construct distorted input for CIFAR training using the Reader ops.\n",
    "        Returns:\n",
    "          images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n",
    "          labels: Labels. 1D tensor of [batch_size] size.\n",
    "        Raises:\n",
    "          ValueError: If no data_dir\n",
    "        \"\"\"\n",
    "        if not data_dir:\n",
    "            raise ValueError('Please supply a data_dir')\n",
    "        data_dir = os.path.join(data_dir, 'cifar-10-batches-bin')\n",
    "        dataset = self.distorted_inputs(data_dir=data_dir)\n",
    "        return dataset\n",
    "\n",
    "    def get_test_inputs(self, data_dir=datadir):\n",
    "        \"\"\"Construct distorted input for CIFAR test using the Reader ops.\n",
    "        Returns:\n",
    "          images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n",
    "          labels: Labels. 1D tensor of [batch_size] size.\n",
    "        Raises:\n",
    "          ValueError: If no data_dir\n",
    "        \"\"\"\n",
    "        if not data_dir:\n",
    "            raise ValueError('Please supply a data_dir')\n",
    "        data_dir = os.path.join(data_dir, 'cifar-10-batches-bin')\n",
    "        dataset = self.distorted_test_inputs(data_dir=data_dir)\n",
    "        return dataset\n",
    "\n",
    "\n",
    "\n",
    "    def distorted_inputs(self, data_dir):\n",
    "        \"\"\"Construct distorted input for CIFAR training using the Reader ops.\n",
    "        Args:\n",
    "          data_dir: Path to the CIFAR-10 data directory.\n",
    "          batch_size: Number of images per batch.\n",
    "        Returns:\n",
    "          images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n",
    "          labels: Labels. 1D tensor of [batch_size] size.\n",
    "        \"\"\"\n",
    "        filenames = [os.path.join(data_dir, 'data_batch_%d.bin' % i)\n",
    "                     for i in range(1, 6)]\n",
    "\n",
    "        return self.__get_dataset(filenames, augmentation=True)\n",
    "\n",
    "    def distorted_test_inputs(self, data_dir):\n",
    "        \"\"\"Construct distorted input for CIFAR training using the Reader ops.\n",
    "        Args:\n",
    "          data_dir: Path to the CIFAR-10 data directory.\n",
    "          batch_size: Number of images per batch.\n",
    "        Returns:\n",
    "          images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n",
    "          labels: Labels. 1D tensor of [batch_size] size.\n",
    "        \"\"\"\n",
    "        filenames = [os.path.join(data_dir, 'test_batch.bin')]\n",
    "\n",
    "        return self.__get_dataset(filenames)\n",
    "\n",
    "\n",
    "    def __get_dataset(self, filenames, augmentation=False):\n",
    "        for f in filenames:\n",
    "            if not tf.gfile.Exists(f):\n",
    "                raise ValueError('Failed to find file: ' + f)\n",
    "\n",
    "        # Dimensions of the images in the CIFAR-10 dataset.\n",
    "        # See http://www.cs.toronto.edu/~kriz/cifar.html for a description of the\n",
    "        # input format.\n",
    "        label_bytes = 1  # 2 for CIFAR-100\n",
    "        height = 32\n",
    "        width = 32\n",
    "        depth = 3\n",
    "        image_bytes = height * width * depth\n",
    "        # Every record consists of a label followed by the image, with a\n",
    "        # fixed number of bytes for each.\n",
    "        record_bytes = label_bytes + image_bytes\n",
    "\n",
    "        new_height = 28\n",
    "        new_width = 28\n",
    "\n",
    "        dataset = tf.data.FixedLengthRecordDataset(filenames, record_bytes=record_bytes)\n",
    "\n",
    "        def transform(value):\n",
    "            # Convert from a string to a vector of uint8 that is record_bytes long.\n",
    "            record_bytes = tf.decode_raw(value, tf.uint8)\n",
    "\n",
    "            # The first bytes represent the label, which we convert from uint8->int32.\n",
    "            label = tf.strided_slice(record_bytes, [0], [label_bytes])\n",
    "            label = tf.cast(label, tf.uint8)\n",
    "            label = tf.reshape(label, shape=[])\n",
    "            label = tf.one_hot(label, depth=10)\n",
    "\n",
    "            # label = tf.one_hot(label, depth=NUM_CLASSES)\n",
    "\n",
    "            # The remaining bytes after the label represent the image, which we reshape\n",
    "            # from [depth * height * width] to [depth, height, width].\n",
    "            image = tf.strided_slice(record_bytes, [label_bytes], [label_bytes + image_bytes])\n",
    "\n",
    "\n",
    "            # Convert from [depth, height, width] to [height, width, depth].\n",
    "            image = tf.reshape(image, [depth, height, width])\n",
    "            image = tf.transpose(image, [1, 2, 0])\n",
    "\n",
    "            ### resize image\n",
    "            # image_file = tf.gfile.FastGFile(filenames[i], 'rb').read()\n",
    "            # image = tf.image.decode_jpeg(image)\n",
    "#             image = tf.image.rgb_to_grayscale(image)\n",
    "#             image = tf.image.resize_images(image, [new_height, new_width])\n",
    "            # image_data = tf.image.convert_image_dtype(image_data, dtype=tf.uint8)\n",
    "            image = tf.cast(image, dtype=tf.float32)\n",
    "            # image = tf.cast(image, dtype=tf.uint8)\n",
    "\n",
    "            # if augmentation:\n",
    "            #\n",
    "            #     # Image processing for training the network. Note the many random\n",
    "            #     # distortions applied to the image.\n",
    "            #\n",
    "            #     # Randomly crop a [height, width] section of the image.\n",
    "            #     distorted_image = tf.random_crop(image, [height, width, 3])\n",
    "            #\n",
    "            #     # Randomly flip the image horizontally.\n",
    "            #     distorted_image = tf.image.random_flip_left_right(distorted_image)\n",
    "            #\n",
    "            #     # Because these operations are not commutative, consider randomizing\n",
    "            #     # the order their operation.\n",
    "            #     # NOTE: since per_image_standardization zeros the mean and makes\n",
    "            #     # the stddev unit, this likely has no effect see tensorflow#1458.\n",
    "            #     distorted_image = tf.image.random_brightness(distorted_image,\n",
    "            #                                                  max_delta=63)\n",
    "            #     distorted_image = tf.image.random_contrast(distorted_image,\n",
    "            #                                                lower=0.2, upper=1.8)\n",
    "            #     image = distorted_image\n",
    "\n",
    "#             image = tf.image.per_image_standardization(image)\n",
    "            image = tfconvert(image)\n",
    "            return image, label\n",
    "\n",
    "#         dataset = dataset.map(map_func=transform, num_parallel_calls=8)\n",
    "        dataset = dataset.apply(tf.contrib.data.map_and_batch(map_func=transform, batch_size=self.batch_size, num_parallel_batches=8))\n",
    "                                \n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputData:\n",
    "    def __init__(self):\n",
    "        # Import MNIST data\n",
    "        from tensorflow.examples.tutorials.mnist import input_data\n",
    "        self.mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True, source_url='http://yann.lecun.com/exdb/mnist/')\n",
    "\n",
    "        self.Input_shape = [-1, 28, 28, 1]\n",
    "        self.X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "\n",
    "    def next_train_batch(self, n=32):\n",
    "        next, _ = self.mnist.train.next_batch(n)\n",
    "        return np.reshape(next, (-1, 28, 28, 1))\n",
    "\n",
    "    def next_test_batch(self, n=32):\n",
    "        next, _ = self.mnist.train.next_batch(n)\n",
    "        return np.reshape(next, (-1, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\" Auto Encoder Example.\n",
    "# Build a 2 layers auto-encoder with TensorFlow to compress images to a\n",
    "# lower latent space and then reconstruct them.\n",
    "# References:\n",
    "#     Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. \"Gradient-based\n",
    "#     learning applied to document recognition.\" Proceedings of the IEEE,\n",
    "#     86(11):2278-2324, November 1998.\n",
    "# Links:\n",
    "#     [MNIST Dataset] http://yann.lecun.com/exdb/mnist/\n",
    "# Author: Aymeric Damien\n",
    "# Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "# \"\"\"\n",
    "\n",
    "# print('start')\n",
    "\n",
    "\n",
    "# TENSORBOARD_PATH = '/tmp/tensorboard/log'\n",
    "# # Training Parameters\n",
    "# learning_rate = 0.01\n",
    "# num_steps = 1\n",
    "# batch_size = 32\n",
    "\n",
    "# display_step = 1000\n",
    "# examples_to_show = 10\n",
    "\n",
    "# # Network Parameters\n",
    "# num_hidden_1 = 256 # 1st layer num features\n",
    "# num_hidden_2 = 128 # 2nd layer num features (the latent dim)\n",
    "# num_input = 784 # MNIST data input (img shape: 28*28)\n",
    "\n",
    "# tf.reset_default_graph()\n",
    "# # tf Graph input (only pictures)\n",
    "\n",
    "# mode = tf.placeholder(tf.bool)\n",
    "\n",
    "# weights = {\n",
    "#     'encoder_h1': tf.Variable(tf.random_normal([num_input, num_hidden_1])),\n",
    "#     'encoder_h2': tf.Variable(tf.random_normal([num_hidden_1, num_hidden_2])),\n",
    "#     'decoder_h1': tf.Variable(tf.random_normal([num_hidden_2, num_hidden_1])),\n",
    "#     'decoder_h2': tf.Variable(tf.random_normal([num_hidden_1, num_input])),\n",
    "# }\n",
    "# biases = {\n",
    "#     'encoder_b1': tf.Variable(tf.random_normal([num_hidden_1])),\n",
    "#     'encoder_b2': tf.Variable(tf.random_normal([num_hidden_2])),\n",
    "#     'decoder_b1': tf.Variable(tf.random_normal([num_hidden_1])),\n",
    "#     'decoder_b2': tf.Variable(tf.random_normal([num_input])),\n",
    "# }\n",
    "\n",
    "# def max_unpool_2x2(x, output_shape):\n",
    "#     out = tf.concat([x, tf.zeros_like(x)], 3)\n",
    "#     out = tf.concat([out, tf.zeros_like(out)], 2)\n",
    "#     out_size = output_shape\n",
    "#     return tf.reshape(out, out_size)\n",
    "\n",
    "# def max_pool_2x2(x):\n",
    "#     _, argmax = tf.nn.max_pool_with_argmax(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding = 'SAME')\n",
    "#     pool = tf.nn.max_pool(x, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "#     return pool, argmax\n",
    "\n",
    "# # Building the encoder\n",
    "# def encoder(x):\n",
    "#     # Encoder Hidden layer with sigmoid activation #1\n",
    "#     layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['encoder_h1']),\n",
    "#                                    biases['encoder_b1']))\n",
    "#     # Encoder Hidden layer with sigmoid activation #2\n",
    "#     layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']),\n",
    "#                                    biases['encoder_b2']))\n",
    "#     return layer_2\n",
    "\n",
    "\n",
    "# # Building the decoder\n",
    "# def decoder(x):\n",
    "#     # Decoder Hidden layer with sigmoid activation #1\n",
    "#     layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h1']),\n",
    "#                                    biases['decoder_b1']))\n",
    "#     # Decoder Hidden layer with sigmoid activation #2\n",
    "#     layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['decoder_h2']),\n",
    "#                                    biases['decoder_b2']))\n",
    "#     return layer_2\n",
    "\n",
    "# # Building the encoder\n",
    "# def encoder_cnn(layer):\n",
    "#     # Encoder Hidden layer with sigmoid activation #1\n",
    "#     layer = tf.layers.conv2d(inputs=layer, filters=64, kernel_size=[3, 3], strides=[1, 1], padding='same', activation=tf.nn.relu, kernel_regularizer=None, name='conv1')\n",
    "#     layer = tf.layers.max_pooling2d(inputs=layer, pool_size=[2, 2], strides=[2, 2], padding='same', name = 'max_pool')\n",
    "#     layer = tf.layers.conv2d(inputs=layer, filters=32, kernel_size=[3, 3], strides=[1, 1], padding='same', activation=tf.nn.relu, kernel_regularizer=None, name='conv2')\n",
    "#     layer = tf.layers.max_pooling2d(inputs=layer, pool_size=[2, 2], strides=[2, 2], padding='same', name = 'max_pool')\n",
    "#     layer = tf.layers.flatten(inputs=layer, name='flatten_c')\n",
    "#     layer = tf.layers.dense(inputs=layer, activation=tf.nn.relu, units=10, name='fc_e1')\n",
    "\n",
    "#     # layer = tf.layers.batch_normalization(inputs=x, training=mode)\n",
    "#     return layer\n",
    "\n",
    "\n",
    "# # Building the decoder\n",
    "# def decoder_cnn(layer):\n",
    "#     layer = tf.layers.dense(inputs=layer, activation=tf.nn.sigmoid, units=49, name='fc_d1')\n",
    "#     layer = tf.reshape(tensor=layer, shape=[-1, 7, 7, 1])\n",
    "#     layer = tf.image.resize_nearest_neighbor(images=layer, size=[layer.shape[1] * 2, layer.shape[2] * 2])\n",
    "#     layer = tf.layers.conv2d_transpose(inputs=layer, filters=32, kernel_size=[3, 3], strides=[1, 1], padding='same', activation=tf.nn.sigmoid, name='conv_trans1')\n",
    "#     layer = tf.image.resize_nearest_neighbor(images=layer, size=[layer.shape[1] * 2, layer.shape[2] * 2])\n",
    "#     layer = tf.layers.conv2d_transpose(inputs=layer, filters=64, kernel_size=[3, 3], strides=[1, 1], padding='same', activation=tf.nn.sigmoid, name='conv_trans2')\n",
    "#     layer = tf.layers.flatten(inputs=layer, name='flatten_d')\n",
    "#     layer = tf.layers.dense(inputs=layer, activation=tf.nn.sigmoid, units=784, name='fc_d2')\n",
    "#     layer = tf.reshape(tensor=layer, shape=Input_shape)\n",
    "#     return layer\n",
    "\n",
    "# input = InputData()\n",
    "# Input_shape = input.Input_shape\n",
    "\n",
    "# # Construct model\n",
    "# encoder_op = encoder_cnn(input.X)\n",
    "# decoder_op = decoder_cnn(encoder_op)\n",
    "\n",
    "# # Prediction\n",
    "# y_pred = decoder_op\n",
    "# # Targets (Labels) are the input data.\n",
    "# y_true = input.X\n",
    "\n",
    "# # Define loss and optimizer, minimize the squared error\n",
    "# loss = tf.losses.mean_squared_error(y_pred, y_true)\n",
    "# optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "# # Initialize the variables (i.e. assign their default value)\n",
    "# init = tf.global_variables_initializer()\n",
    "\n",
    "# # Start Training\n",
    "# # Start a new TF session\n",
    "\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "\n",
    "#     if tf.gfile.Exists(TENSORBOARD_PATH):\n",
    "#         tf.gfile.DeleteRecursively(TENSORBOARD_PATH)\n",
    "#     tf.gfile.MakeDirs(TENSORBOARD_PATH)\n",
    "\n",
    "#     summary_writer = tf.summary.FileWriter(TENSORBOARD_PATH, sess.graph)\n",
    "\n",
    "#     # Run the initializer\n",
    "#     sess.run(init)\n",
    "\n",
    "#     # Training\n",
    "#     for i in range(1, num_steps+1):\n",
    "#         # Prepare Data\n",
    "#         # Get the next batch of MNIST data (only images are needed, not labels)\n",
    "#         batch_x = input.next_train_batch(batch_size)\n",
    "\n",
    "#         # Run optimization op (backprop) and cost op (to get loss value)\n",
    "#         _, l = sess.run([optimizer, loss], feed_dict={input.X: batch_x})\n",
    "#         # Display logs per step\n",
    "#         if i % display_step == 0 or i == 1:\n",
    "#             print('Step %i: Minibatch Loss: %f' % (i, l))\n",
    "\n",
    "#         loss_summary = tf.Summary()\n",
    "#         loss_summary.value.add(tag='loss', simple_value = l)\n",
    "#         summary_writer.add_summary(loss_summary, global_step=i)\n",
    "\n",
    "#     # Testing\n",
    "#     # Encode and decode images from test set and visualize their reconstruction.\n",
    "#     n = 4\n",
    "#     input_cifar = Cifar10data(n)\n",
    "#     # MNIST test set\n",
    "#     batch_x = input.next_test_batch(n)\n",
    "#     # Encode and decode the digit image\n",
    "#     recontruct = sess.run(decoder_op, feed_dict={input.X: batch_x})\n",
    "    \n",
    "#     tf.summary.image('mnist_original', batch_x, collections=['image_mnist'])\n",
    "#     tf.summary.image('mnist_reconstruct', recontruct, collections=['image_mnist'])          \n",
    "#     merge = tf.summary.merge_all(key='image_mnist')\n",
    "    \n",
    "#     summary = sess.run(merge)\n",
    "#     summary_writer.add_summary(summary)    \n",
    "\n",
    "#     # cifar test set\n",
    "#     cifar_x = input_cifar.next_train_batch(sess)\n",
    "#     # Encode and decode the digit image\n",
    "#     reconstruct_cifar = sess.run(decoder_op, feed_dict={input.X: cifar_x})    \n",
    "\n",
    "#     tf.summary.image('cifar_original', cifar_x, collections=['image_cifar'])    \n",
    "#     tf.summary.image('cifar_reconstruct', reconstruct_cifar, collections=['image_cifar'])       \n",
    "#     merge_cifar = tf.summary.merge_all(key='image_cifar')\n",
    "     \n",
    "#     summary_cifar = sess.run(merge_cifar)\n",
    "#     summary_writer.add_summary(summary_cifar)\n",
    "    \n",
    "#     summary_writer.flush()\n",
    "# print('end')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "#git clone\n",
    "#https://github.com/tensorflow/compression\n",
    "\n",
    "sys.path.append('/home/ubuntu/github/compression')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_v1(layer):    \n",
    "    #shape (-1, w, h, c)\n",
    "    with tf.variable_scope(\"forward_v1\", reuse=tf.AUTO_REUSE):\n",
    "        layer = tf.layers.conv2d(inputs=layer, filters=64, kernel_size=[3, 3], strides=[1, 1], padding='same', activation=tf.nn.relu, kernel_regularizer=None, name='conv1')\n",
    "        layer = tf.layers.max_pooling2d(inputs=layer, pool_size=[2, 2], strides=[2, 2], padding='same', name = 'max_pool1')\n",
    "        layer = tf.layers.conv2d(inputs=layer, filters=32, kernel_size=[3, 3], strides=[1, 1], padding='same', activation=tf.nn.relu, kernel_regularizer=None, name='conv2')\n",
    "        layer = tf.layers.max_pooling2d(inputs=layer, pool_size=[2, 2], strides=[2, 2], padding='same', name = 'max_pool2')\n",
    "        #shape (-1, w/4, h/4, 32)    \n",
    "        layer = tf.layers.conv2d(inputs=layer, filters=3, kernel_size=[3, 3], strides=[1, 1], padding='valid', activation=None, kernel_regularizer=None, name='conv3')\n",
    "        #shape (-1, w/4 - 2, h/4 -2, 3)\n",
    "    #    layer = tf.layers.flatten(inputs=layer, name='flatten_c')\n",
    "    #    layer = tf.layers.dense(inputs=layer, activation=tf.nn.relu, units=10, name='fc_e1')\n",
    "    return layer\n",
    "\n",
    "def backward_v1(layer):\n",
    "#     layer = tf.layers.dense(inputs=layer, activation=tf.nn.sigmoid, units=49, name='fc_d1')\n",
    "#     layer = tf.reshape(tensor=layer, shape=[-1, 7, 7, 1])\n",
    "    with tf.variable_scope(\"backward_v1\", reuse=tf.AUTO_REUSE):\n",
    "        layer = tf.layers.conv2d_transpose(inputs=layer, filters=32, kernel_size=[3, 3], strides=[1, 1], padding='valid', activation=None, name='conv_trans3')\n",
    "        layer = tf.image.resize_nearest_neighbor(images=layer, size=[tf.shape(layer)[1] * 2, tf.shape(layer)[2] * 2])\n",
    "        layer = tf.layers.conv2d_transpose(inputs=layer, filters=64, kernel_size=[3, 3], strides=[1, 1], padding='same', activation=tf.nn.sigmoid, name='conv_trans1')\n",
    "        layer = tf.image.resize_nearest_neighbor(images=layer, size=[tf.shape(layer)[1] * 2, tf.shape(layer)[2] * 2])\n",
    "        layer = tf.layers.conv2d_transpose(inputs=layer, filters=1, kernel_size=[3, 3], strides=[1, 1], padding='same', activation=tf.nn.sigmoid, name='conv_trans2')\n",
    "    #     layer = tf.layers.flatten(inputs=layer, name='flatten_d')\n",
    "    #     layer = tf.layers.dense(inputs=layer, activation=tf.nn.sigmoid, units=784, name='fc_d2')\n",
    "        layer = tf.reshape(tensor=layer, shape=Input_shape)\n",
    "    return layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_v2(layer):\n",
    "    #shape (-1, w, h, c)\n",
    "    with tf.variable_scope(\"forward_v2\", reuse=tf.AUTO_REUSE):\n",
    "        layer = tf.layers.conv2d(inputs=layer, filters=64, kernel_size=[5, 5], strides=[2, 2], padding='same', activation=tf.nn.relu, kernel_regularizer=None, name='conv1')\n",
    "#         layer = tf.layers.max_pooling2d(inputs=layer, pool_size=[2, 2], strides=[2, 2], padding='same', name = 'max_pool1')\n",
    "        layer = tf.contrib.layers.gdn(layer, name='gdn1')\n",
    "\n",
    "        layer = tf.layers.conv2d(inputs=layer, filters=64, kernel_size=[5, 5], strides=[2, 2], padding='same', activation=tf.nn.relu, kernel_regularizer=None, name='conv2')\n",
    "#         layer = tf.layers.max_pooling2d(inputs=layer, pool_size=[2, 2], strides=[2, 2], padding='same', name = 'max_pool2')\n",
    "        layer = tf.contrib.layers.gdn(layer, name='gdn2')\n",
    "\n",
    "#         layer = tf.layers.conv2d(inputs=layer, filters=64, kernel_size=[3, 3], strides=[1, 1], padding='same', activation=tf.nn.relu, kernel_regularizer=None, name='conv3')\n",
    "        # layer = tf.layers.max_pooling2d(inputs=layer, pool_size=[2, 2], strides=[2, 2], padding='same', name = 'max_pool2')\n",
    "#         layer = tf.contrib.layers.gdn(layer, name='gdn3')\n",
    "        \n",
    "        layer = tf.layers.conv2d(inputs=layer, filters=3, kernel_size=[5, 5], strides=[2, 2], padding='same', activation=tf.identity, kernel_regularizer=None, name='conv4')\n",
    "        # [-1, 7, 7, 5]\n",
    "        # [-1, 8, 8, 5]\n",
    "    return layer\n",
    "\n",
    "def backward_v2(layer):\n",
    "    with tf.variable_scope(\"backward_v2\", reuse=tf.AUTO_REUSE):\n",
    "        layer = tf.layers.conv2d_transpose(inputs=layer, filters=64, kernel_size=[5, 5], strides=[2, 2], padding='same', activation=tf.identity, kernel_regularizer=None, name='conv4_transpose')\n",
    "\n",
    "#         layer = tf.contrib.layers.gdn(layer, inverse=True, name='igdn3')\n",
    "        # layer = tf.image.resize_nearest_neighbor(images=layer, size=[tf.shape(layer)[1] * 2, tf.shape(layer)[2] * 2])\n",
    "#         layer = tf.layers.conv2d_transpose(inputs=layer, filters=64, kernel_size=[3, 3], strides=[1, 1], padding='same', activation=tf.nn.sigmoid, kernel_regularizer=None, name='conv3_transpose')\n",
    "        \n",
    "        layer = tf.contrib.layers.gdn(layer, inverse=True, name='igdn2')\n",
    "#         layer = tf.image.resize_nearest_neighbor(images=layer, size=[tf.shape(layer)[1] * 2, tf.shape(layer)[2] * 2])\n",
    "        layer = tf.layers.conv2d_transpose(inputs=layer, filters=64, kernel_size=[5, 5], strides=[2, 2], padding='same', activation=tf.nn.sigmoid, kernel_regularizer=None, name='conv2_transpose')\n",
    "\n",
    "#         layer = tf.layers.conv2d_transpose(inputs=layer, filters=20, kernel_size=[3, 3], strides=[1, 1], padding='same', activation=tf.nn.sigmoid, kernel_regularizer=None, name='conv1_5_transpose')\n",
    "        \n",
    "        layer = tf.contrib.layers.gdn(layer, inverse=True, name='igdn1')\n",
    "#         layer = tf.image.resize_nearest_neighbor(images=layer, size=[tf.shape(layer)[1] * 2, tf.shape(layer)[2] * 2])\n",
    "        layer = tf.layers.conv2d_transpose(inputs=layer, filters=3, kernel_size=[5, 5], strides=[2, 2], padding='same', activation=tf.identity, kernel_regularizer=None, name='conv1_transpose')\n",
    "#         layer = tf.reshape(tensor=layer, shape=Input_shape)\n",
    "\n",
    "    return layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_v3(layer):\n",
    "    #shape (-1, w, h, c)\n",
    "    with tf.variable_scope(\"forward_v3\", reuse=tf.AUTO_REUSE):\n",
    "        layer = tf.layers.conv2d(inputs=layer, filters=16, kernel_size=[5, 5], strides=[1, 1], padding='same', activation=tf.nn.relu, kernel_regularizer=None, name='conv1')\n",
    "        layer = tf.layers.max_pooling2d(inputs=layer, pool_size=[2, 2], strides=[2, 2], padding='same', name = 'max_pool1')\n",
    "        layer = tf.contrib.layers.gdn(layer, name='gdn1')\n",
    "\n",
    "        layer = tf.layers.conv2d(inputs=layer, filters=32, kernel_size=[5, 5], strides=[1, 1], padding='same', activation=tf.nn.relu, kernel_regularizer=None, name='conv2')\n",
    "        layer = tf.layers.max_pooling2d(inputs=layer, pool_size=[2, 2], strides=[2, 2], padding='same', name = 'max_pool2')\n",
    "        layer = tf.contrib.layers.gdn(layer, name='gdn2')\n",
    "\n",
    "        layer = tf.layers.conv2d(inputs=layer, filters=5, kernel_size=[3, 3], strides=[1, 1], padding='same', activation=None, kernel_regularizer=None, name='conv3')\n",
    "        # [-1, 7, 7, 5]\n",
    "        # [-1, 8, 8, 5]\n",
    "    return layer\n",
    "\n",
    "def backward_v3(layer):\n",
    "    with tf.variable_scope(\"backward_v3\", reuse=tf.AUTO_REUSE):\n",
    "        layer = tf.layers.conv2d_transpose(inputs=layer, filters=32, kernel_size=[3, 3], strides=[1, 1], padding='same', activation=None, kernel_regularizer=None, name='conv3_transpose')\n",
    "\n",
    "        layer = tf.contrib.layers.gdn(layer, inverse=True, name='igdn2')\n",
    "        layer = tf.image.resize_nearest_neighbor(images=layer, size=[tf.shape(layer)[1] * 2, tf.shape(layer)[2] * 2])\n",
    "        layer = tf.layers.conv2d_transpose(inputs=layer, filters=16, kernel_size=[5, 5], strides=[1, 1], padding='same', activation=tf.nn.sigmoid, kernel_regularizer=None, name='conv2_transpose')\n",
    "\n",
    "        layer = tf.contrib.layers.gdn(layer, inverse=True, name='igdn1')\n",
    "        layer = tf.image.resize_nearest_neighbor(images=layer, size=[tf.shape(layer)[1] * 2, tf.shape(layer)[2] * 2])\n",
    "        layer = tf.layers.conv2d_transpose(inputs=layer, filters=3, kernel_size=[5, 5], strides=[1, 1], padding='same', activation=None, kernel_regularizer=None, name='conv1_transpose')\n",
    "#         layer = tf.reshape(tensor=layer, shape=Input_shape)\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name learning rate decay is illegal; using learning_rate_decay instead.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import compression.python.layers.entropybottleneck\n",
    "from compression.python.layers.entropybottleneck import EntropyBottleneck\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "def forward_transform(layer):    \n",
    "    return forward_v2(layer)\n",
    "\n",
    "def backward_transform(layer):\n",
    "    return backward_v2(layer)\n",
    "\n",
    "Input_shape = [-1, 32, 32, 3]\n",
    "\n",
    "# Build autoencoder.\n",
    "x = tf.placeholder(tf.float32, shape=[None, 32, 32, 3])\n",
    "y = forward_transform(x)\n",
    "\n",
    "# with tf.variable_scope(\"entropy_bottleneck\", reuse=tf.AUTO_REUSE):\n",
    "entropy_bottleneck = EntropyBottleneck()\n",
    "y_, likelihoods = entropy_bottleneck(y, training=True)\n",
    "\n",
    "# y_ = y   \n",
    "x_ = backward_transform(y_)\n",
    "\n",
    "# print(likelihoods)\n",
    "# Information content (= predicted codelength) in bits of each batch element\n",
    "# (note that taking the natural logarithm and dividing by `log(2)` is\n",
    "# equivalent to taking base-2 logarithms):\n",
    "bits = tf.reduce_sum(tf.log(likelihoods), axis=(1, 2, 3)) / -np.log(2)\n",
    "\n",
    "# Squared difference of each batch element:\n",
    "squared_error = tf.reduce_sum(tf.squared_difference(x, x_), axis=(1, 2, 3))\n",
    "\n",
    "learning_rate_decay = tf.train.exponential_decay(1e-4, global_step=0, decay_steps=5000, decay_rate=0.95, staircase=True, name='exponential_decay_learning_rate')\n",
    "learning_rate_summary_op = tf.summary.scalar('learning rate decay', learning_rate_decay, collections=['learning_rate'])\n",
    "\n",
    "# The loss is a weighted sum of mean squared error and entropy (average\n",
    "# information content), where the weight controls the trade-off between\n",
    "# approximation error and entropy.\n",
    "# main_loss = 0.5 * tf.reduce_mean(squared_error) + tf.reduce_mean(bits)\n",
    "main_loss = tf.reduce_mean(squared_error) + 0.1 * tf.reduce_mean(bits)\n",
    "# main_loss = tf.reduce_mean(squared_error)\n",
    "# main_loss = tf.losses.mean_squared_error(x, x_)\n",
    "\n",
    "# Training operations\n",
    "# decay_learning_rate = tf.train.exponential_decay(learning_rate=1e-4, \n",
    "#                                            global_step=global_step, \n",
    "#                                            decay_steps=100), \n",
    "#                                            decay_rate=0.95, \n",
    "#                                            staircase=True)\n",
    "    \n",
    "# Minimize loss and auxiliary loss, and execute update op.\n",
    "main_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate_decay)\n",
    "main_step = main_optimizer.minimize(main_loss, global_step=global_step)\n",
    "# 1e-3 is a good starting point for the learning rate of the auxiliary loss,\n",
    "# assuming Adam is used.\n",
    "aux_optimizer = tf.train.AdamOptimizer(learning_rate=1e-3)\n",
    "aux_step = aux_optimizer.minimize(entropy_bottleneck.losses[0], global_step=global_step)\n",
    "group_op = tf.group(main_step, aux_step, entropy_bottleneck.updates[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "Step 1: Minibatch main loss: 1389.603516, bottleneck loss: 123.001389\n",
      "Step 1000: Minibatch main loss: 166.540878, bottleneck loss: 117.652985\n",
      "Step 2000: Minibatch main loss: 165.353180, bottleneck loss: 111.154053\n",
      "Step 3000: Minibatch main loss: 150.643997, bottleneck loss: 104.424881\n",
      "Step 4000: Minibatch main loss: 162.383820, bottleneck loss: 98.555153\n",
      "Step 5000: Minibatch main loss: 164.846512, bottleneck loss: 93.745583\n",
      "Step 6000: Minibatch main loss: 156.305237, bottleneck loss: 89.812317\n",
      "Step 7000: Minibatch main loss: 144.610489, bottleneck loss: 85.625969\n",
      "Step 8000: Minibatch main loss: 145.794388, bottleneck loss: 81.347725\n",
      "Step 9000: Minibatch main loss: 151.148438, bottleneck loss: 76.860649\n",
      "Step 10000: Minibatch main loss: 158.819809, bottleneck loss: 72.130005\n",
      "Step 11000: Minibatch main loss: 142.818314, bottleneck loss: 66.985657\n",
      "Step 12000: Minibatch main loss: 135.086929, bottleneck loss: 61.894085\n",
      "Step 13000: Minibatch main loss: 163.727036, bottleneck loss: 56.620098\n",
      "Step 14000: Minibatch main loss: 146.250427, bottleneck loss: 51.292824\n",
      "Step 15000: Minibatch main loss: 165.178787, bottleneck loss: 45.954296\n",
      "Step 16000: Minibatch main loss: 137.130798, bottleneck loss: 40.786690\n",
      "Step 17000: Minibatch main loss: 154.936661, bottleneck loss: 34.946205\n",
      "Step 18000: Minibatch main loss: 144.293442, bottleneck loss: 29.533794\n",
      "Step 19000: Minibatch main loss: 166.144257, bottleneck loss: 25.498877\n",
      "Step 20000: Minibatch main loss: 158.115250, bottleneck loss: 22.891268\n",
      "Step 21000: Minibatch main loss: 127.918343, bottleneck loss: 20.447905\n",
      "Step 22000: Minibatch main loss: 153.331223, bottleneck loss: 18.015476\n",
      "Step 23000: Minibatch main loss: 129.846313, bottleneck loss: 15.250383\n",
      "Step 24000: Minibatch main loss: 142.918854, bottleneck loss: 14.424483\n",
      "Step 25000: Minibatch main loss: 148.512146, bottleneck loss: 13.671206\n",
      "Step 26000: Minibatch main loss: 154.245911, bottleneck loss: 12.819898\n",
      "Step 27000: Minibatch main loss: 139.246170, bottleneck loss: 12.105146\n",
      "Step 28000: Minibatch main loss: 146.858887, bottleneck loss: 10.928177\n",
      "Step 29000: Minibatch main loss: 138.154419, bottleneck loss: 10.272069\n",
      "Step 30000: Minibatch main loss: 162.672714, bottleneck loss: 9.649471\n",
      "Step 31000: Minibatch main loss: 134.804703, bottleneck loss: 8.659269\n",
      "Step 32000: Minibatch main loss: 141.051102, bottleneck loss: 7.911053\n",
      "Step 33000: Minibatch main loss: 158.924240, bottleneck loss: 6.943723\n",
      "Step 34000: Minibatch main loss: 153.754913, bottleneck loss: 6.392188\n",
      "Step 35000: Minibatch main loss: 148.468292, bottleneck loss: 5.534704\n",
      "Step 36000: Minibatch main loss: 157.271561, bottleneck loss: 4.714109\n",
      "Step 37000: Minibatch main loss: 162.608322, bottleneck loss: 3.972334\n",
      "Step 38000: Minibatch main loss: 168.485550, bottleneck loss: 2.942727\n",
      "Step 39000: Minibatch main loss: 134.844360, bottleneck loss: 2.258050\n",
      "Step 40000: Minibatch main loss: 151.852585, bottleneck loss: 1.531113\n",
      "Step 41000: Minibatch main loss: 144.541046, bottleneck loss: 0.666214\n",
      "Step 42000: Minibatch main loss: 149.975296, bottleneck loss: 0.210451\n",
      "Step 43000: Minibatch main loss: 137.912979, bottleneck loss: 0.146698\n",
      "Step 44000: Minibatch main loss: 141.346710, bottleneck loss: 0.115749\n",
      "Step 45000: Minibatch main loss: 140.728958, bottleneck loss: 0.344007\n",
      "Step 46000: Minibatch main loss: 147.473785, bottleneck loss: 0.184949\n",
      "Step 47000: Minibatch main loss: 138.375259, bottleneck loss: 0.244746\n",
      "Step 48000: Minibatch main loss: 142.742386, bottleneck loss: 0.264947\n",
      "Step 49000: Minibatch main loss: 137.741089, bottleneck loss: 0.173849\n",
      "Step 50000: Minibatch main loss: 143.481384, bottleneck loss: 0.206111\n",
      "Step 51000: Minibatch main loss: 132.888062, bottleneck loss: 0.393176\n",
      "Step 52000: Minibatch main loss: 122.546875, bottleneck loss: 0.086854\n",
      "Step 53000: Minibatch main loss: 132.373352, bottleneck loss: 0.080249\n",
      "Step 54000: Minibatch main loss: 145.748886, bottleneck loss: 0.206632\n",
      "Step 55000: Minibatch main loss: 154.512558, bottleneck loss: 0.341357\n",
      "Step 56000: Minibatch main loss: 127.179344, bottleneck loss: 0.126475\n",
      "Step 57000: Minibatch main loss: 136.877853, bottleneck loss: 0.081420\n",
      "Step 58000: Minibatch main loss: 133.794907, bottleneck loss: 0.205488\n",
      "Step 59000: Minibatch main loss: 127.811096, bottleneck loss: 0.200856\n",
      "Step 60000: Minibatch main loss: 127.116257, bottleneck loss: 0.098903\n",
      "shape Tensor(\"strided_slice_4:0\", shape=(3,), dtype=int32)\n",
      "string length: [24, 22, 26, 22, 20, 22, 22, 24, 20, 24, 22, 22, 20, 20, 26, 26, 20, 24, 20, 20, 22, 24, 22, 20, 22, 22, 20, 22, 20, 26, 24, 22] * 32\n",
      "model: /tempssd/mnist_autoencoder/save/2018_Jun_22_10_26_21/model/best_test_accuracy \n",
      "summary: /tempssd/mnist_autoencoder/save/2018_Jun_22_10_26_21/summary\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "SAVE_PATH = '/tempssd/mnist_autoencoder/save/'\n",
    "\n",
    "timestring = strftime(\"%Y_%b_%d_%H_%M_%S\", gmtime())\n",
    "default_dir = os.path.join(SAVE_PATH, timestring)\n",
    "summmary_path = os.path.join(default_dir, 'summary')\n",
    "if not (os.path.isdir(summmary_path)):\n",
    "    os.makedirs(summmary_path)\n",
    "\n",
    "model_path = os.path.join(default_dir, 'model')\n",
    "if not (os.path.isdir(model_path)):\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "best_test_accuracy_dir = os.path.join(model_path, \"best_test_accuracy\")\n",
    "if not (os.path.isdir(best_test_accuracy_dir)):\n",
    "    os.makedirs(best_test_accuracy_dir)\n",
    "    \n",
    "best_test_accuracy_model_name = os.path.join(best_test_accuracy_dir, \"step\")\n",
    "\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Start Training\n",
    "# Start a new TF session\n",
    "\n",
    "num_steps = 60000\n",
    "TENSORBOARD_PATH = '/tmp/tensorboard/log'\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "display_step = 1000\n",
    "\n",
    "input = InputData()\n",
    "input_cifar = Cifar10data(batch_size)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    summary_writer = tf.summary.FileWriter(summmary_path, sess.graph)\n",
    "        \n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "    \n",
    "    best_test_accuracy = 10000\n",
    "\n",
    "    # Training\n",
    "    for i in range(1, num_steps+1):\n",
    "        # Prepare Data\n",
    "        # Get the next batch of MNIST data (only images are needed, not labels)\n",
    "        batch_x = input_cifar.next_train_batch(sess)\n",
    "\n",
    "        # Run optimization op (backprop) and cost op (to get loss value)\n",
    "        _, ml, bnl, learning_rate_summary = sess.run([group_op, main_loss, entropy_bottleneck.losses[0], learning_rate_summary_op], feed_dict={x: batch_x})\n",
    "#         _, ml = sess.run([main_step, main_loss], feed_dict={x: batch_x})\n",
    "        # Display logs per step\n",
    "        if i % display_step == 0 or i == 1:\n",
    "            print('Step %i: Minibatch main loss: %f, bottleneck loss: %f' % (i, ml, bnl))\n",
    "#             print('Step %i: Minibatch main loss: %f' % (i, ml))\n",
    "\n",
    "        step = global_step.eval()\n",
    "\n",
    "        summary_writer.add_summary(learning_rate_summary, global_step=step)\n",
    "    \n",
    "        main_loss_summary = tf.Summary()\n",
    "        main_loss_summary.value.add(tag='main loss', simple_value = ml)\n",
    "        summary_writer.add_summary(main_loss_summary, global_step=step)\n",
    "        \n",
    "        bottleneck_loss_summary = tf.Summary()\n",
    "        bottleneck_loss_summary.value.add(tag='bottleneck loss', simple_value = bnl)\n",
    "        summary_writer.add_summary(bottleneck_loss_summary, global_step=step)\n",
    "        \n",
    "        if best_test_accuracy > ml:\n",
    "            best_test_accuracy = ml\n",
    "            best_test_step = step\n",
    "            tf.train.Saver().save(sess, save_path=best_test_accuracy_model_name, global_step=step)\n",
    "    \n",
    "    # MNIST test set\n",
    "    \n",
    "    # Encode and decode the digit image\n",
    "    #x = tf.placeholder(tf.float32, shape=[None, 28, 28, 1])\n",
    "    #y = forward_transform(x)\n",
    "\n",
    "    strings = entropy_bottleneck.compress(y)\n",
    "# #     tf.cast(strings, tf.string)\n",
    "    \n",
    "    \n",
    "    shape = tf.shape(y)[1:]\n",
    "    print(\"shape {}\".format(shape))\n",
    "    \n",
    "# #     tf.cast(shape, tf.int32)    \n",
    "\n",
    "# #     with tf.variable_scope(\"entropy_bottleneck\", reuse=tf.AUTO_REUSE):\n",
    "# #         entropy_bottleneck_evak = EntropyBottleneck()(y, training=False)\n",
    "# #         y_, likelihoods = entropy_bottleneck(y, training=True)\n",
    "\n",
    "#     ry_ = entropy_bottleneck.decompress(strings, shape, channels=3)   \n",
    "#     rx_ = backward_transform(ry_)\n",
    "    \n",
    "    ry_, likelihoods = entropy_bottleneck(y, training=False)\n",
    "#     ry_ = y_\n",
    "    rx_ = backward_transform(ry_)\n",
    "#     rx_ = x_\n",
    "\n",
    "    \n",
    "#     n = 3\n",
    "# #     input_cifar = Cifar10data(n)\n",
    "#     batch_x = input.next_test_batch(n)\n",
    "    \n",
    "#     recontruct= sess.run(rx_, feed_dict={x: batch_x})\n",
    "\n",
    "#     tf.summary.image('mnist_original', batch_x, collections=['image_mnist'])\n",
    "#     tf.summary.image('mnist_reconstruct', recontruct, collections=['image_mnist'])          \n",
    "#     merge = tf.summary.merge_all(key='image_mnist')\n",
    "\n",
    "#     summary = sess.run(merge)\n",
    "#     summary_writer.add_summary(summary) \n",
    "\n",
    "    # cifar test set\n",
    "    cifar_x = input_cifar.next_test_batch(sess)\n",
    "    # Encode and decode the digit image\n",
    "    reconstruct_cifar, string_value = sess.run([rx_, strings], feed_dict={x: cifar_x})    \n",
    "    \n",
    "    string_value = [len(s) for s in string_value]\n",
    "    print(\"string length: {} * {}\".format(string_value, len(string_value)))\n",
    "    \n",
    "    tf.summary.image('cifar_original', tfrevert(cifar_x), collections=['image_cifar'])    \n",
    "    tf.summary.image('cifar_reconstruct', tfrevert(reconstruct_cifar), collections=['image_cifar'])       \n",
    "    merge_cifar = tf.summary.merge_all(key='image_cifar')\n",
    "\n",
    "    summary_cifar = sess.run(merge_cifar)\n",
    "    summary_writer.add_summary(summary_cifar)\n",
    "    \n",
    "\n",
    "    summary_writer.flush()    \n",
    "        \n",
    "    if not (os.path.isdir(os.path.dirname(TENSORBOARD_PATH))):\n",
    "        os.makedirs(os.path.dirname(TENSORBOARD_PATH))\n",
    "    \n",
    "    if os.path.exists(TENSORBOARD_PATH):\n",
    "        os.unlink(TENSORBOARD_PATH)  \n",
    "    \n",
    "    os.symlink(summmary_path, TENSORBOARD_PATH)\n",
    "\n",
    "print(\"model: {} \\nsummary: {}\".format(best_test_accuracy_dir, summmary_path))\n",
    "\n",
    "print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
